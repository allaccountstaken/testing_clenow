{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "# Change path to where you have the data\n",
    "path = '\\\\data\\\\random_stocks\\\\'\n",
    "\n",
    "\"\"\"Ingest function needs this exact signature\"\"\"\n",
    "\n",
    "def random_stock_data(environ,\n",
    "                      asset_db_writer,\n",
    "                      minute_bar_writer,\n",
    "                      daily_bar_writer,\n",
    "                      adjustment_writer,\n",
    "                      calendar,\n",
    "                      start_session,\n",
    "                      end_session,\n",
    "                      cache,\n",
    "                      show_progress,\n",
    "                      output_dir\n",
    "                     ):\n",
    "    # Get list of files from path\n",
    "    # Slicing off teh last part\n",
    "    # 'example.csv'[:-4] = 'example'\n",
    "    symbols = [f[:-4] for f in listdir(path)]\n",
    "    \n",
    "    if not symbols:\n",
    "        raise ValueError(\"No symbols found in the folder\")\n",
    "        \n",
    "    # Prepare an empty DataFrame for dividends\n",
    "    divs = pd.DataFrame(columns=['sid',\n",
    "                                 'amount',\n",
    "                                 'ex_date',\n",
    "                                 'record_date',\n",
    "                                 'declared_date',\n",
    "                                 'pay_date'\n",
    "                                ]\n",
    "                       )\n",
    "    \n",
    "    # Prepare an empty DataFrame for splits\n",
    "    splits = pd.DateFrame(columns=['sid',\n",
    "                                   'ratio',\n",
    "                                   'effective_date'\n",
    "                                  ])\n",
    "    \n",
    "    # Prepare an empty DataFrame for metadata\n",
    "    metadata = pd.DataFrame(columns=['start_date',\n",
    "                                     'end_date',\n",
    "                                     'auto_close_date',\n",
    "                                     'symbol',\n",
    "                                     'exchange'\n",
    "                                    ])\n",
    "    \n",
    "    # Check valid trading dates, according to the selected exchange calendar\n",
    "    sessions = calendar.sessions_in_range(start_session, end_session)\n",
    "    \n",
    "    # Get data for all stocks and wrtite to Zipline\n",
    "    daily_bar_writer.write(process_stocks(symbols, sessions, metadata, divs))\n",
    "    \n",
    "    # Write the metadata\n",
    "    asset_db_writer.write(equities=metadata)\n",
    "    \n",
    "    # Write splits and dividends\n",
    "    adjustments_writer.write(splits=splits, dividends=divs)\n",
    "    \n",
    "    \n",
    "\"\"\"Generator function to iterate stocks, \n",
    "build historical data, metadata, and dividend data\"\"\"\n",
    "def process_stocks(symbol, sessions, metadata, divs):\n",
    "    # Loop the stocks, setting a unique Security ID (SID)\n",
    "    for sid, symbol in enumerate(symbols):\n",
    "        print('Loading {} ...'.format(symbol))\n",
    "        # Read the stock data from csv file\n",
    "        df = pd.read_csv('{}/{}.csv'.format(path, symbol), index_col=[0], parse_dates=[0])\n",
    "        \n",
    "        # Check first and last date\n",
    "        start_date = df.index[0]\n",
    "        end_date = df.index[-1]\n",
    "        \n",
    "        # Synch to the official exchange calendar\n",
    "        df = df.reindex(sessions.tz_localize(None))[start_date : end_date]\n",
    "        \n",
    "        # Forward fill missing data\n",
    "        df.fillna(method='ffill', inplace=True)\n",
    "        \n",
    "        # Drop remaining Nana\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # The auto_close date is teh day after the last trade\n",
    "        ac_date = end_date + pd.Timedelta(days=1)\n",
    "        \n",
    "        # Add a row to the metadata DataFrame. Don't forget to add an exchange field\n",
    "        metadata.loc[sid] = start_date, end_date, ac_date, symbol, 'NYSE'\n",
    "        \n",
    "        # If there's dividend data, add that to the dividend DataFrame\n",
    "        if 'dividend' in df.columns:\n",
    "            \n",
    "            # Slice off the days with dividends\n",
    "            tmp = df[df['dividend'] != 0.0]['dividend']\n",
    "            div = pd.DataFrame(data=tmp.index.tolist(), columns=['ex_date'])\n",
    "            \n",
    "            \n",
    "            # Provide emty columns as we don't have these data now\n",
    "            div['record_date'] = pd.NaT\n",
    "            div['declared_date'] = pd.NaT\n",
    "            div['pay_date'] = pd.NaT\n",
    "            \n",
    "            # Store the dividends and set teh Security ID\n",
    "            div['amount'] = tmp.tolist()\n",
    "            div['sid'] = sid\n",
    "            \n",
    "            # Start numbering at where we left last time\n",
    "            ind = pd.Index(range(divs.shape[0], divs.shape[0] + div.shape[0]))\n",
    "            div.set_index(ind, inplace=True)\n",
    "            \n",
    "            # Append thios stock's dividend to the list of all dividends\n",
    "            divs = divs.append(div)\n",
    "            \n",
    "        yield sid, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"/Users/dmitrymikhaylov/Documents/code/fin/testing_clenow/data/random_stocks/\"\n",
    "df = pd.read_csv('{}/{}.csv'.format(d, 'AAL'), index_col=[0], parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulding futures_bundle\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from tqdm import tqdm # this is used for progress bar\n",
    "\n",
    "# Change path to where you have the data\n",
    "base_path = '/Users/dmitrymikhaylov/Documents/code/fin/testing_clenow/data/'\n",
    "data_path = base_path + 'random_futures'\n",
    "meta_path = 'futures_meta/meta.csv'\n",
    "futures_lookup = pd.read_csv(base_path + meta_path, index_col=0)\n",
    "\n",
    "\"\"\"\n",
    "The ingest function needs these exact signature, meaning these arguments below:\n",
    "\"\"\"\n",
    "def random_futures_data(environ,\n",
    "                      asset_db_writer,\n",
    "                      minute_bar_writer,\n",
    "                      daily_bar_writer,\n",
    "                      adjustment_writer,\n",
    "                      calendar,\n",
    "                      start_session,\n",
    "                      end_session,\n",
    "                      cache,\n",
    "                      show_progress,\n",
    "                      output_dir\n",
    "                     ):\n",
    "    # Prepare an empty DataFrame for dividends\n",
    "    divs = pd.DataFrame(columns=['sid', \n",
    "                                 'amount',\n",
    "                                 'ex_date',\n",
    "                                 'record_date',\n",
    "                                 'declared_date',\n",
    "                                 'pay_date'\n",
    "                                ]\n",
    "                       )\n",
    "    \n",
    "    # Prepare and empty DataFrame for splits\n",
    "    splits = pd.DataFrame(columns=['sid',\n",
    "                                   'ratio',\n",
    "                                   'effective_date'\n",
    "                                  ]\n",
    "                         )\n",
    "    \n",
    "    # Prepare an empty DataFrame for metadata\n",
    "    metadata = pd.DataFrame(columns=['start_date',\n",
    "                                     'end_date', \n",
    "                                     'auto_close_date',\n",
    "                                     'symbol',\n",
    "                                     'root_symbol',\n",
    "                                     'expiration_date',\n",
    "                                     'notice_date',\n",
    "                                     'tick_size',\n",
    "                                     'exchange'\n",
    "                                    ]\n",
    "                           )\n",
    "    \n",
    "    # Check valid trading dates, according to the selected exchange calendar\n",
    "    sessions = calendar.sessions_in_range(start_session, end_session)\n",
    "    \n",
    "    # Get data for all stocks and write to Zipline\n",
    "    daily_bar_writer.write(process_futures(symbols, sessions, metadata))\n",
    "    adjustment_writer.write(splits=splits, dividends=divs)\n",
    "    \n",
    "    # Prepare root level metadata\n",
    "    root_symbols = futures_lookup.copy()\n",
    "    root_symbols['root_symbol_id'] = root_symbols.index.values\n",
    "    del root_symbols['minor_fx_adj']\n",
    "    \n",
    "    # Write the meta data\n",
    "    asset_db_writer.write(futures=metadata, root_symbols=root_symbols)\n",
    "    \n",
    "    \n",
    "def process_futures(symbols, sessions, metadata):\n",
    "    # Loop the stocks, setting a unique Security ID (SID)\n",
    "    sid = 0\n",
    "    \n",
    "    # Loop the symbols with process bar, using tqdm\n",
    "    for symbol in tqdm(symbols, desc='Loading data...'):\n",
    "        sid += 1\n",
    "        \n",
    "        # Read the stock data from csv file\n",
    "        df = pd.read_csv('{}/{}.csv'.format(data_path, symbol), index_col=[0], parse_dates=[0])\n",
    "        \n",
    "        # Check for minor currency quotes\n",
    "        adjustment_factor = futures_lookup.loc[\n",
    "            futures_lookup['root_symbol'] == df.iloc[0]['root_symbol']]['minor_fx_adj'].iloc[0]\n",
    "        \n",
    "        df['open'] *= adjustment_factor\n",
    "        df['high'] *= adjustment_factor\n",
    "        df['low'] *= adjustment_factor\n",
    "        df['close'] *= adjustment_factor\n",
    "        \n",
    "        # Avoid potential high / low data errors in data set\n",
    "        # And apply minor currency adjustments for USc quotes\n",
    "        df['high'] = df[['high', 'close']].max(axis=1)\n",
    "        df['low'] = df[['high', 'close']].min(axis=1)\n",
    "        df['high'] = df[['high', 'open']].max(axis=1)\n",
    "        df['low'] = df[['low', 'open']].min(axis=1)\n",
    "        \n",
    "        # Synch to the official exchange calendar\n",
    "        df = df.reindex(sessions.tz_localize(None))[df.index[0]:df.index[-1]]\n",
    "        \n",
    "        # Forward fill missing data\n",
    "        df.fillna(method='ffill', inplace=True)\n",
    "        \n",
    "        # Drop remaining NaN\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # Cut dates before 2000\n",
    "        df = df['2000-01-01']\n",
    "        \n",
    "        make_meta(sid, metadata, sessions)\n",
    "        \n",
    "        del df['openinterest']\n",
    "        del df['expiration_date']\n",
    "        del df['root_symbol']\n",
    "        del df['symbol']\n",
    "        \n",
    "        yield sid, df\n",
    "\n",
    "        \n",
    "def make_meta(sid, metadata, df, sessions):\n",
    "    # Check first and last date\n",
    "    start_date = df.index[0]\n",
    "    end_date = df.index[-1]\n",
    "    \n",
    "    # The auto_close date is the day after the last trade\n",
    "    ac_date = end_date + pd.Timedelta(days=1)\n",
    "    \n",
    "    symbol = df.iloc[0]['symbol']\n",
    "    root_sym = df.iloc[0]['root_symbol']\n",
    "    exchng = futures_lookup.loc[futures_lookup['root_symbol'] == root_sym]['exchange'].iloc[0]\n",
    "    exp_date = end_date\n",
    "    \n",
    "    # Add notice day if you have one\n",
    "    # Tip: set notice date to one month prior ro expiry for commodity markets\n",
    "    notice_date = ac_date\n",
    "    tick_size = 0.0001 # Placeholder\n",
    "    \n",
    "    # Add a row to the metadata DataFrame\n",
    "    metadata.loc[sid] = start_date, end_date, ac_date, symbol, \\\n",
    "    root_sym, exp_date, notice_date, tick_size, exchng"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
